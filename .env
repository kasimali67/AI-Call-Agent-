WIT_AI_TOKEN=A3KZTFWMT3LNX3ZRIR6LQ67AFYFEE7GE
PORT=80
TWILIO_ACCOUNT_SID=AC3a98cba9a73cdf56d412ccb3cda0bc85
TWILIO_AUTH_TOKEN=35c1b473c673dbc873b5e5e379f2c641
PUBLIC_WEBSOCKET_URL=wss://13f9-2409-40c1-400d-2de0-a5c7-90df-1943-3566.ngrok-free.app /media-stream
VOSK_MODEL_PATH=C:/Users/Kasimali/ai-customer-support/vosk-model-small-en-us-0.15
#TWILIO_PHONE_NUMBER= +1(615)-434-9218
#uvicorn main:app --host 0.0.0.0 --port 505 --reload
#ngrok http 505
#/incoming-call
# Optionally, you can also implement a media stream endpoint for raw audio processing using Vosk.
# Uncomment the code below if you want to use a WebSocket-based media stream.

# from fastapi import WebSocket, WebSocketDisconnect

# @app.websocket("/media-stream")
# async def media_stream(websocket: WebSocket):
#     """
#     WebSocket endpoint for receiving audio from Twilio Media Streams.
#     Processes audio with Vosk for Speech-to-Text and updates the call with a reply.
#     """
#     logger.info("Client connected to media-stream")
#     await websocket.accept()
#     recognizer = KaldiRecognizer(vosk_model, 16000)  # Assumes 16kHz mono audio
#     
#     # For demonstration, get a Call SID from active_calls if available.
#     call_sid = next(iter(active_calls)) if active_calls else None
#     if not call_sid:
#         logger.warning("No active Call SID found; dynamic update might not work.")
#     
#     try:
#         while True:
#             message = await websocket.receive()
#             if message["type"] == "websocket.disconnect":
#                 logger.info("WebSocket disconnected")
#                 break
#             
#             data = None
#             if message["type"] == "websocket.receive":
#                 if "bytes" in message and message["bytes"]:
#                     data = message["bytes"]
#                 elif "text" in message and message["text"]:
#                     data = message["text"].encode("utf-8")
#             
#             if data is None:
#                 continue
#             
#             if recognizer.AcceptWaveform(data):
#                 result = recognizer.Result()
#                 result_dict = json.loads(result)
#                 recognized_text = result_dict.get("text", "")
#                 logger.info("Final recognized text: %s", recognized_text)
#                 if recognized_text:
#                     reply = process_user_input(recognized_text)
#                     if call_sid:
#                         update_call_response(call_sid, reply)
#                     await websocket.send_json({
#                         "recognized": recognized_text,
#                         "reply": reply
#                     })
#             else:
#                 partial_result = recognizer.PartialResult()
#                 partial_dict = json.loads(partial_result)
#                 logger.debug("Partial recognized text: %s", partial_dict)
#                 await websocket.send_json({"partial": partial_dict})
#     except WebSocketDisconnect:
#         logger.info("Client disconnected from media-stream")
#
